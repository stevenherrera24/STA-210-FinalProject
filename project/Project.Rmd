---
title: "What Makes the Best Tennis Player?"
author: "Steven Herrera and Ethan Shen"
date: "11/09/2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, message=F,include=F}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.kable.NA = '')
```

# Loaded Packages

```{r load-packages, message=FALSE}
library(tidyverse)
library(olsrr)
library(cowplot)
library(car)
library(broom)
library(knitr)
library(arm)
library(tidyr)
library(pROC)
library(arm)
library(rlm)
```

# Data Manipulation

```{r message=FALSE}
atp <- read_csv("files/atp.csv")
atp2016 <- read_csv("files/atp2016.csv")
atp2015 <- read_csv("files/atp2015.csv")
atp2014 <- read_csv("files/atp2014.csv")
atp2013 <- read_csv("files/atp2013.csv")
atp2012 <- read_csv("files/atp2012.csv")
atp2011 <- read_csv("files/atp2011.csv")
atp2010 <- read_csv("files/atp2010.csv")

atp1 <- atp %>%
  filter(tourney_date < 20171113)

winners2016 <- atp2016 %>%
  filter(tourney_date < 20161114)

winners2015 <- atp2015 %>%
  filter(tourney_date < 20151115) 

winners2014 <- atp2014 %>%
  filter(tourney_date < 20141109) 

winners2013 <- atp2013 %>%
  filter(tourney_date < 20131104) 

winners2012 <- atp2012 %>%
  filter(tourney_date < 20121105) 

winners2011 <- atp2011 %>%
  filter(tourney_date < 20111114) 

winners2010 <- atp2010 %>%
  filter(tourney_date < 20101121) 

winners <- rbind(atp1, winners2016, winners2015, winners2014, winners2013, 
                 winners2012, winners2011, winners2010)

winners_set <- winners %>%
  filter(best_of == 3,
         !is.na(w_ace), 
         !is.na(w_df), 
         !is.na(w_svpt), 
         !is.na(w_1stIn), 
         !is.na(w_1stWon), 
         !is.na(w_2ndWon),
         !is.na(w_SvGms), 
         !is.na(w_bpSaved),
         !is.na(w_bpFaced),
         surface!="None")

losers <- winners_set %>%
  mutate(seed = loser_seed,
         name = loser_name,
         hand = loser_hand,
         ht = loser_ht,
         age = loser_age,
         rank = loser_rank,
         rankpoints = loser_rank_points,
         ace = l_ace,
         df = l_df,
         svpt = l_svpt,
         firsstIn = l_1stIn,
         firsttWon = l_1stWon,
         secondndWon = l_2ndWon,
         SvGms = l_SvGms,
         bpSaved = l_bpSaved,
         bpFaced = l_bpFaced,
         minutes = minutes,
         status = 0
         )  
  

winners <- winners_set %>%
  mutate(seed = winner_seed,
         name = winner_name,
         hand = winner_hand,
         ht = winner_ht,
         age = winner_age,
         rank = winner_rank,
         rankpoints = winner_rank_points,
         ace = w_ace,
         df = w_df,
         svpt = w_svpt,
         firsstIn = w_1stIn,
         firsttWon = w_1stWon,
         secondndWon = w_2ndWon,
         SvGms = w_SvGms,
         bpSaved = w_bpSaved,
         bpFaced = w_bpFaced,
         minutes = minutes,
         status = 1
         ) 
tennis <- rbind(winners,losers)

tennis <- tennis %>%
  filter(!is.na(seed),
         !is.na(name),
         !is.na(hand),
         !is.na(ht),
         !is.na(age),
         !is.na(rank),
         !is.na(rankpoints),
         !is.na(ace),
         !is.na(df),
         !is.na(svpt),
         !is.na(firsstIn),
         !is.na(firsttWon),
         !is.na(secondndWon),
         !is.na(SvGms),
         !is.na(bpSaved),
         !is.na(bpFaced),
         !is.na(minutes),
         !is.na(status))
```

# Data 

Using data manipulation skills in R, we shaped the dataset to show each observation as the outcome of the match for the winner and the loser of each match from 2010-2017. Below, is a glimpse of our dataset.

```{r}
glimpse(tennis)
```

Because we have 11,037 observations, we will randomly select observations to be included in a smaller dataset so that we can effectively examine exploratory data analysis. Below, is our code on how we randomly selected the observations in our new dataset.

```{r}
set.seed(1234)
ten <- tennis %>% sample_n(1000)
```

Here is what our new dataset looks like:

```{r}
glimpse(ten)
```

# Exploratory Data Analysis 

To begin our exploratory data analysis, we will examine a matrix plot of the variables in our dataset to consider multicollinearity and large leverage of certain observations.

## Matrix Plot
```{r fig.height=11, fig.width=11}
ten <- ten %>%
  mutate(status = as.factor(status)) 

pairs(status ~ minutes + ht + age + rank + rankpoints + ace +
        df + svpt + firsstIn + firsttWon + secondndWon + 
        SvGms + bpSaved + bpFaced, data=ten, pch = 16,
      main = "Matrix of scatterplots for Tournament Wins and Variables")
```

Looking at the matrix plot, we will already consider removing the following favirables because of multicollinearity: `svpt`, `firsstIn`, `firsttWon`, `secondndWon`, `SvGms`, and `bpFaced`.

We will now look at box plots of the numeric variables we will include in our full model:

```{r fig.height=10, fig.width=8, message=FALSE}
p1 <- ggplot(data=ten,aes(x=status,y=minutes, group=status)) +
  geom_boxplot() + 
  labs(title="Minutes by Status",
       x = "0 if Lost, 1 if Won",
       y = "Minutes")
p2 <- ggplot(data=ten,aes(x=status,y=ht, group=status)) +
  geom_boxplot() + 
  labs(title="Height by Status",
       x = "0 if Lost, 1 if Won",
       y = "Height")
p3 <- ggplot(data=ten,aes(x=status,y=age, group=status)) +
  geom_boxplot() + 
  labs(title="Age by Status",
       x = "0 if Lost, 1 if Won",
       y = "Age (years)")
p4 <- ggplot(data=ten,aes(x=status,y=rank, group=status)) +
  geom_boxplot() + 
  labs(title="Ranking by Status",
       x = "0 if Lost, 1 if Won",
       y = "Rank")
p5 <- ggplot(data=ten,aes(x=status,y=rankpoints, group=status)) +
  geom_boxplot() + 
  labs(title="Rankpoints by Status",
       x = "0 if Lost, 1 if Won",
       y = "Rankpoints")
p6 <- ggplot(data=ten,aes(x=status,y=ace, group=status)) +
  geom_boxplot() + 
  labs(title="Aces by Status",
       x = "0 if Lost, 1 if Won",
       y = "Aces")
p7 <- ggplot(data=ten,aes(x=status,y=df, group=status)) +
  geom_boxplot() + 
  labs(title="Double Faults by Status",
       x = "0 if Lost, 1 if Won",
       y = "Double Faults")
p8 <- ggplot(data=ten,aes(x=status,y=bpSaved, group=status)) +
  geom_boxplot() + 
  labs(title="Saved Breakpoints by Status",
       x = "0 if Lost, 1 if Won",
       y = "Saved Breakpoints")

plot_grid(p1,p2,p3,p4,p5,
          p6,p7,p8,ncol=2)
```

And we will include a stacked bar graph for the variable `surface`.

```{r}
ggplot(data=ten,aes(x=surface, fill = status)) + geom_bar(position = "fill") + 
  labs(title="Status vs. Surface")
```

In looking at all of these observations, it seems like the medians of the numeric distributions do not seem to differ that much by status of winning or losing. The same can be said about the proportions of winning and losing matches against all three surfaces. In creating our model, it could be difficult to see which variables could be helpful in differentiating between whether a player will win a match or not. But, we hope to see that a combination of these variables will be helpful in determining a model that best predicts the percentage of winning a match.

# Logistic Regression Model

To begin our regression models, we will use all of the variables we deemed important from our exploratory data analysis.

```{r}
full_model <- glm(status ~ minutes + ht + age + rank + 
                rankpoints + ace + df + bpSaved + surface, 
                family=binomial,data=ten)
kable(tidy(full_model), format="markdown", digits = 3)

```

```{r}
full_w_interactions <- glm(status ~ minutes + ht + age + rank + 
                rankpoints + ace + df + bpSaved + surface + surface * minutes +
                surface * ht + surface * age + surface * rank + surface * rankpoints + 
                surface * ace + surface * df + surface * bpSaved,
                family=binomial,data=ten)
```

```{r}
tidy(anova(full_model, full_w_interactions, test = "Chisq"))
```


```{r}
model.selected.interactions <- step(full_w_interactions,direction="backward")
```

# Model

```{r}
final.base.model <- model.selected.interactions
kable(tidy(final.base.model), format = "markdown", digits = 3)
```

# Model Assessment

## Binned Plots with Residuals vs Predicted

```{r}
ten <- ten %>% mutate(Residuals = residuals.glm(final.base.model,type="response"),
                          Predicted = predict.glm(final.base.model,type="response"))

binnedplot(ten$Predicted, ten$Residuals,xlab="Predicted Probabilities",
           ylab="Residuals",main="Binned Residuals vs. Predicted Probabilities")
```

```{r,fig.height=4,fig.width=4,echo=F}
binnedplot(ten$minutes, ten$Residuals,xlab="Minutes",
           ylab="Residuals",main="Binned Residuals vs. Minutes")

binnedplot(ten$ht, ten$Residuals,xlab="Height",
           ylab="Residuals",main="Binned Residuals vs. Height")

binnedplot(ten$rankpoints, ten$Residuals,xlab="Rankpoints",
           ylab="Residuals",main="Binned Residuals vs. Rankpoints")

binnedplot(ten$ace, ten$Residuals,xlab="Aces",
           ylab="Residuals",main="Binned Residuals vs. Aces")

binnedplot(ten$df, ten$Residuals,xlab="Double Faults",
           ylab="Residuals",main="Binned Residuals vs. Double Faults")

binnedplot(ten$bpSaved, ten$Residuals,xlab="Saved break podints",
           ylab="Residuals",main="Binned Residuals vs. Saved break points")
```

```{r}
ROC.ten <- roc(ten$status,ten$Predicted,plot=T)
```

```{r}
ROC.ten$auc
```

```{r}
threshold = 0.30
table(ten$status, ten$Predicted > threshold)
```

```{r}
(326 + 13)/(14+13+326+635)
```


# Linear Regression Assumptions: Revised

Unfortunately, one of our residuals plots has a non-linear relationship. Thus, we will remove `bpSaved` from the model. 

```{r}
newten <- ten
final <- glm(status ~ minutes + ht + rankpoints + ace + df + surface + surface * ht + surface * ace + surface * df, family = binomial, data = newten)
kable(tidy(final), format = "markdown", digits = 3)
```

# Model Assessment

## Binned Plots with Residuals vs Predicted

```{r}
newten <- newten %>% mutate(Residuals = residuals.glm(final,type="response"),
                          Predicted = predict.glm(final,type="response"))

binnedplot(newten$Predicted, newten$Residuals,xlab="Predicted Probabilities",
           ylab="Residuals",main="Binned Residuals vs. Predicted Probabilities")
```

```{r,fig.height=4,fig.width=4,echo=F}
binnedplot(newten$minutes, newten$Residuals,xlab="Minutes",
           ylab="Residuals",main="Binned Residuals vs. Minutes")

binnedplot(newten$ht, newten$Residuals,xlab="Height",
           ylab="Residuals",main="Binned Residuals vs. Height")

binnedplot(newten$ace, newten$Residuals,xlab="Aces",
           ylab="Residuals",main="Binned Residuals vs. Aces")

binnedplot(newten$df, newten$Residuals,xlab="Double Faults",
           ylab="Residuals",main="Binned Residuals vs. Double Faults")

binnedplot(newten$rankpoints, newten$Residuals,xlab="Rankpoints",
           ylab="Residuals",main="Binned Residuals vs. Rankpoints")
```

```{r}
ROC.newten <- roc(newten$status,newten$Predicted,plot=T)
```

```{r}
ROC.newten$auc
```

```{r}
threshold = 0.30
table(newten$status, newten$Predicted > threshold)
```

```{r}
(326 + 13)/(14+13+326+635)
```


# Prediction

## Test cases: 

We will look at a match that was played the Monte Carlo Masters in 2014 between Roger Federer and Novak Djokovic. We want to see the probability that a player will win the match. 

```{r message=FALSE}
tennis %>%
  filter(tourney_name == "Monte Carlo Masters",
         name == "Roger Federer" |  name == "Novak Djokovic",
         tourney_id == "2014-410",
         loser_name == "Novak Djokovic")
```

```{r}
fed <- data.frame(minutes = 75, ht = 185, rankpoints = 5355 , ace = 3 , df = 1, surface="Hard")
djo1 <- data.frame(minutes = 75, ht = 188, rankpoints = 11680, ace = 2, df = 0, surface="Hard")
predict.glm(final, newdata=fed, type="response")
predict.glm(final, newdata=djo1, type="response")
```

We see that the model predicts Roger Federer has a 77.09% chance of winning the match, while Novak Djokovic has a 92.52% chance of winning the match. This is mainly because Djokovic's rank points were almost double that of Federer's at the time. However, Federer won the match. In this case, we had an anomaly. 

The next match we will look at was played at the China Open in 2013 and was between Novak Djokovic and Rafael Nadal.

```{r}
tennis %>%
  filter(name == "Novak Djokovic" | name == "Rafael Nadal",
         tourney_name == "Beijing",
         loser_name == "Rafael Nadal",
         tourney_id == "2013-747")

```
```{r}
djo2 <- data.frame(minutes = 87, ht = 188, rankpoints = 11120, ace = 5, df = 1)
nadal <- data.frame(minutes = 87, ht = 185, rankpoints = 10860, ace = 2, df = 2)
predict.glm(final, newdata=djo2, type="response")
predict.glm(final, newdata=nadal, type="response")
```
We see that the model predicts Novak Djokovic has a 91.7% chance of winning the match, while Rafael Nadal has a 87.51% chance of winning the match. Djokovic won the match. 

### Test Case with Similar Rank Points 

Now, we'll look at a match where both players had similar rank points. The match we will look at is between Jo Wilfried Tsonga and Michael Llodra, and was played at the Queen's Club Championships in 2011. 

```{r}
ten %>%
  filter(winner_rank_points > 1000 & winner_rank_points < 2000 & loser_rank_points > 1000 & loser_rank_points < 2000,
         tourney_id == "2011-311",
         tourney_name == "Queen's Club",
         winner_name == "Jo Wilfried Tsonga"
         )
```

```{r}
jo <- data.frame(minutes = 23, ht = 188, rankpoints = 1480, ace = 2, df = 1, surface = "Grass")
llodra <- data.frame(minutes = 23, ht = 190, rankpoints = 1400, ace = 0, df = 0, surface = "Grass")
predict.glm(final, newdata=jo, type="response")
predict.glm(final, newdata=llodra, type="response")
```

We see that the model predicts Jo Wilfried Tsonga has a 36.46% of chance of winning the match, while Michael Llodra has a 18.91% chance of winning the match. These percentages are lower because the players' rankpoints are significantly lower than those of Nadal's and Djokovic's. 

# Conclusion








